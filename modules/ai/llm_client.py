"""
LLM Client - Ð¾Ð±ÐµÑ€Ñ‚ÐºÐ° Ð½Ð°Ð´ DeepSeek/OpenAI API (Ð¸ÑÐ¿Ð¾Ð»ÑŒÐ·ÑƒÐµÑ‚ OpenAI SDK)
"""
import os
import json
import logging
from typing import Optional, Dict, Any
from openai import OpenAI

logger = logging.getLogger(__name__)


class LLMClient:
    """
    ÐšÐ»Ð¸ÐµÐ½Ñ‚ Ð´Ð»Ñ Ñ€Ð°Ð±Ð¾Ñ‚Ñ‹ Ñ LLM API (DeepSeek, OpenAI) Ñ‡ÐµÑ€ÐµÐ· OpenAI SDK
    """
    
    # API endpoints
    PROVIDERS = {
        'deepseek': {
            'base_url': 'https://api.deepseek.com',
            'default_model': 'deepseek-chat'
        },
        'openai': {
            'base_url': 'https://api.openai.com/v1',
            'default_model': 'gpt-4o-mini'
        }
    }
    
    def __init__(self, provider: str = None, api_key: str = None, model: str = None):
        """
        Ð˜Ð½Ð¸Ñ†Ð¸Ð°Ð»Ð¸Ð·Ð°Ñ†Ð¸Ñ ÐºÐ»Ð¸ÐµÐ½Ñ‚Ð°
        
        Args:
            provider: 'deepseek' Ð¸Ð»Ð¸ 'openai' (Ð¸Ð· .env AI_PROVIDER)
            api_key: API ÐºÐ»ÑŽÑ‡ (Ð¸Ð· .env AI_API_KEY)
            model: ÐœÐ¾Ð´ÐµÐ»ÑŒ (Ð¸Ð· .env AI_MODEL)
        """
        self.provider = provider or os.getenv('AI_PROVIDER', 'deepseek')
        self.api_key = api_key or os.getenv('AI_API_KEY')
        
        if not self.api_key:
            raise ValueError("AI_API_KEY not set in environment")
        
        provider_config = self.PROVIDERS.get(self.provider)
        if not provider_config:
            raise ValueError(f"Unknown provider: {self.provider}. Use 'deepseek' or 'openai'")
        
        self.base_url = provider_config['base_url']
        self.model = model or os.getenv('AI_MODEL', provider_config['default_model'])
        self.timeout = int(os.getenv('AI_TIMEOUT', 120))
        
        # Ð˜Ð½Ð¸Ñ†Ð¸Ð°Ð»Ð¸Ð·Ð¸Ñ€ÑƒÐµÐ¼ OpenAI ÐºÐ»Ð¸ÐµÐ½Ñ‚
        self.client = OpenAI(
            api_key=self.api_key,
            base_url=self.base_url,
            timeout=self.timeout
        )
        
        logger.info(f"ðŸ¤– LLMClient initialized: {self.provider}/{self.model}")
    
    def ask(self, system_prompt: str, user_prompt: str = None, temperature: float = 0.7) -> str:
        """
        ÐžÑ‚Ð¿Ñ€Ð°Ð²Ð»ÑÐµÑ‚ Ð·Ð°Ð¿Ñ€Ð¾Ñ Ðº LLM Ð¸ Ð²Ð¾Ð·Ð²Ñ€Ð°Ñ‰Ð°ÐµÑ‚ Ñ‚ÐµÐºÑÑ‚Ð¾Ð²Ñ‹Ð¹ Ð¾Ñ‚Ð²ÐµÑ‚
        
        Args:
            system_prompt: Ð¡Ð¸ÑÑ‚ÐµÐ¼Ð½Ñ‹Ð¹ Ð¿Ñ€Ð¾Ð¼Ð¿Ñ‚ (Ñ€Ð¾Ð»ÑŒ, ÐºÐ¾Ð½Ñ‚ÐµÐºÑÑ‚, Ð¸Ð½ÑÑ‚Ñ€ÑƒÐºÑ†Ð¸Ð¸)
            user_prompt: ÐŸÐ¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ñ‚ÐµÐ»ÑŒÑÐºÐ¸Ð¹ Ð¿Ñ€Ð¾Ð¼Ð¿Ñ‚ (Ð¾Ð¿Ñ†Ð¸Ð¾Ð½Ð°Ð»ÑŒÐ½Ð¾)
            temperature: Ð¢ÐµÐ¼Ð¿ÐµÑ€Ð°Ñ‚ÑƒÑ€Ð° (0.0-1.0)
            
        Returns:
            str: Ð¢ÐµÐºÑÑ‚Ð¾Ð²Ñ‹Ð¹ Ð¾Ñ‚Ð²ÐµÑ‚ Ð¾Ñ‚ Ð¼Ð¾Ð´ÐµÐ»Ð¸
        """
        messages = [{"role": "system", "content": system_prompt}]
        
        if user_prompt:
            messages.append({"role": "user", "content": user_prompt})
        
        return self._send_request(messages, temperature=temperature)
    
    def ask_json(self, system_prompt: str, user_prompt: str = None, temperature: float = 0.3) -> Dict[str, Any]:
        """
        ÐžÑ‚Ð¿Ñ€Ð°Ð²Ð»ÑÐµÑ‚ Ð·Ð°Ð¿Ñ€Ð¾Ñ Ðº LLM Ð¸ Ð²Ð¾Ð·Ð²Ñ€Ð°Ñ‰Ð°ÐµÑ‚ JSON Ð¾Ñ‚Ð²ÐµÑ‚
        
        Args:
            system_prompt: Ð¡Ð¸ÑÑ‚ÐµÐ¼Ð½Ñ‹Ð¹ Ð¿Ñ€Ð¾Ð¼Ð¿Ñ‚ (Ð´Ð¾Ð»Ð¶ÐµÐ½ Ñ‚Ñ€ÐµÐ±Ð¾Ð²Ð°Ñ‚ÑŒ JSON)
            user_prompt: ÐŸÐ¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ñ‚ÐµÐ»ÑŒÑÐºÐ¸Ð¹ Ð¿Ñ€Ð¾Ð¼Ð¿Ñ‚ (Ð¾Ð¿Ñ†Ð¸Ð¾Ð½Ð°Ð»ÑŒÐ½Ð¾)
            temperature: Ð¢ÐµÐ¼Ð¿ÐµÑ€Ð°Ñ‚ÑƒÑ€Ð° (Ð½Ð¸Ð¶Ðµ Ð´Ð»Ñ ÐºÐ¾Ð½ÑÐ¸ÑÑ‚ÐµÐ½Ñ‚Ð½Ð¾ÑÑ‚Ð¸)
            
        Returns:
            dict: Ð Ð°ÑÐ¿Ð°Ñ€ÑÐµÐ½Ð½Ñ‹Ð¹ JSON Ð¾Ñ‚Ð²ÐµÑ‚
        """
        messages = [{"role": "system", "content": system_prompt}]
        
        if user_prompt:
            messages.append({"role": "user", "content": user_prompt})
        
        response_text = self._send_request(
            messages, 
            temperature=temperature,
            response_format={"type": "json_object"}
        )
        
        # ÐŸÐ°Ñ€ÑÐ¸Ð¼ JSON
        try:
            return json.loads(response_text)
        except json.JSONDecodeError as e:
            logger.error(f"âŒ Failed to parse JSON response: {e}")
            logger.error(f"Raw response: {response_text[:500]}")
            raise ValueError(f"LLM returned invalid JSON: {e}")
    
    def _send_request(
        self, 
        messages: list, 
        temperature: float = 0.7,
        response_format: dict = None
    ) -> str:
        """
        ÐžÑ‚Ð¿Ñ€Ð°Ð²Ð»ÑÐµÑ‚ Ð·Ð°Ð¿Ñ€Ð¾Ñ Ðº API Ñ‡ÐµÑ€ÐµÐ· OpenAI SDK
        """
        try:
            logger.debug(f"ðŸ“¤ Sending request to {self.provider}...")
            
            # ÐŸÐ¾Ð´Ð³Ð¾Ñ‚Ð¾Ð²ÐºÐ° Ð¿Ð°Ñ€Ð°Ð¼ÐµÑ‚Ñ€Ð¾Ð²
            kwargs = {
                "model": self.model,
                "messages": messages,
                "temperature": temperature,
                "max_tokens": 4000
            }
            
            # Ð”Ð¾Ð±Ð°Ð²Ð»ÑÐµÐ¼ response_format ÐµÑÐ»Ð¸ ÑƒÐºÐ°Ð·Ð°Ð½
            if response_format:
                kwargs["response_format"] = response_format
            
            # ÐžÑ‚Ð¿Ñ€Ð°Ð²Ð»ÑÐµÐ¼ Ð·Ð°Ð¿Ñ€Ð¾Ñ Ñ‡ÐµÑ€ÐµÐ· OpenAI SDK
            response = self.client.chat.completions.create(**kwargs)
            
            # Ð›Ð¾Ð³Ð¸Ñ€ÑƒÐµÐ¼ Ð¸ÑÐ¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ð½Ð¸Ðµ Ñ‚Ð¾ÐºÐµÐ½Ð¾Ð²
            if response.usage:
                logger.info(f"ðŸ“Š Tokens used: {response.usage.total_tokens} "
                           f"(prompt: {response.usage.prompt_tokens}, "
                           f"completion: {response.usage.completion_tokens})")
            
            # Ð˜Ð·Ð²Ð»ÐµÐºÐ°ÐµÐ¼ Ð¾Ñ‚Ð²ÐµÑ‚
            content = response.choices[0].message.content
            
            return content.strip()
            
        except Exception as e:
            logger.error(f"âŒ API error: {e}")
            raise


# Singleton instance Ð´Ð»Ñ ÑƒÐ´Ð¾Ð±ÑÑ‚Ð²Ð°
_client: Optional[LLMClient] = None


def get_llm_client() -> LLMClient:
    """
    Ð’Ð¾Ð·Ð²Ñ€Ð°Ñ‰Ð°ÐµÑ‚ singleton instance LLMClient
    """
    global _client
    
    if _client is None:
        _client = LLMClient()
    
    return _client
